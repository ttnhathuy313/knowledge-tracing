{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>log_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478035</td>\n",
       "      <td>7014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478043</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478053</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478069</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50964</td>\n",
       "      <td>167478041</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     log_id  sequence_id  correct\n",
       "0    50121  167478035         7014      0.0\n",
       "1    50121  167478043         7014      1.0\n",
       "2    50121  167478053         7014      1.0\n",
       "3    50121  167478069         7014      1.0\n",
       "4    50964  167478041         7014      1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_csv = pd.read_csv('./data/data-2015.csv')\n",
    "data_csv.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file `data-2015.csv` is the ASSISTments dataset taken from: https://sites.google.com/site/assistmentsdata/datasets/2015-assistments-skill-builder-data. This dataset records the process of students answering questions in problem sets and their performance. The platform being used to collect data is: https://new.assistments.org/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the dataset contains the information of one student answering one question in a particular problem set.\n",
    "\n",
    "- `user_id`: The id number assigned to each students. Each student has one unique id.\n",
    "- `log_id`: The unique log id appeared in the database when the student answer current question. The larger log id is, the later the question was answered.\n",
    "- `sequence_id`: The id of the problem sets that the question is in.\n",
    "- `correct`: The correctness of the student's answer. It ranges from 0.0 to 1.0, where 0.0 means that the student answered incorrectly on the first attempt and 1.0 means that the student answered correctly on the first attempt. There may be values in between the range, however, for this current model, we only focus on the correct values of 0 and 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>log_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>708631.000000</td>\n",
       "      <td>7.086310e+05</td>\n",
       "      <td>708631.000000</td>\n",
       "      <td>708631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>296232.978276</td>\n",
       "      <td>1.695323e+08</td>\n",
       "      <td>22683.474821</td>\n",
       "      <td>0.725502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48018.650247</td>\n",
       "      <td>3.608096e+06</td>\n",
       "      <td>41593.028018</td>\n",
       "      <td>0.437467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50121.000000</td>\n",
       "      <td>1.509145e+08</td>\n",
       "      <td>5898.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>279113.000000</td>\n",
       "      <td>1.660355e+08</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>299168.000000</td>\n",
       "      <td>1.704579e+08</td>\n",
       "      <td>9424.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>335647.000000</td>\n",
       "      <td>1.723789e+08</td>\n",
       "      <td>14442.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>362374.000000</td>\n",
       "      <td>1.754827e+08</td>\n",
       "      <td>236309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        log_id    sequence_id        correct\n",
       "count  708631.000000  7.086310e+05  708631.000000  708631.000000\n",
       "mean   296232.978276  1.695323e+08   22683.474821       0.725502\n",
       "std     48018.650247  3.608096e+06   41593.028018       0.437467\n",
       "min     50121.000000  1.509145e+08    5898.000000       0.000000\n",
       "25%    279113.000000  1.660355e+08    7020.000000       0.000000\n",
       "50%    299168.000000  1.704579e+08    9424.000000       1.000000\n",
       "75%    335647.000000  1.723789e+08   14442.000000       1.000000\n",
       "max    362374.000000  1.754827e+08  236309.000000       1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes **708631 rows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of missing values for every column\n",
      "user_id        0.0\n",
      "log_id         0.0\n",
      "sequence_id    0.0\n",
      "correct        0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Part of missing values for every column')\n",
    "print(data_csv.isnull().sum() / len(data_csv))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data includes no missing values, we do not have to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique values for every column\n",
      "user_id         19917\n",
      "log_id         708631\n",
      "sequence_id       100\n",
      "correct            11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique values for every column')\n",
    "print(data_csv.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset records 19917 students answering 100 problem sets. Each row has one unique `log_id`. Lastly, there are multiple values of `correct`, however we only focus on the value of 0 and 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the necessary EDA steps when dealing with tabular data in machine learning are:\n",
    "\n",
    "- Check the frequency counts and distribution of the target variable to see if there is any class imbalance or skewness.\n",
    "- Check the distribution of each feature to see if there are any outliers, missing values, or anomalies.\n",
    "- Check the correlation matrix and scatter plots to see how different features are related to each other and to the target variable.\n",
    "- Check the statistical significance of the features using hypothesis testing or feature selection methods to see which ones are important for predicting the target variable.\n",
    "- Check the distributional fit of the features and apply transformations if needed to make them more suitable for machine learning algorithms.\n",
    "- Check for multicollinearity and remove redundant features if needed to avoid overfitting and improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between columns\n",
      "              user_id    log_id  sequence_id   correct\n",
      "user_id      1.000000  0.515198    -0.040369  0.028428\n",
      "log_id       0.515198  1.000000    -0.009621  0.054341\n",
      "sequence_id -0.040369 -0.009621     1.000000 -0.069912\n",
      "correct      0.028428  0.054341    -0.069912  1.000000\n"
     ]
    }
   ],
   "source": [
    "print('Correlation between columns')\n",
    "print(data_csv.corr())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are little correlation from other columns to the `correct` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      variable       VIF\n",
      "0    Intercept  0.000000\n",
      "1      user_id  1.363667\n",
      "2       log_id  1.361571\n",
      "3  sequence_id  1.001803\n"
     ]
    }
   ],
   "source": [
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#find design matrix for regression model using 'rating' as response variable\n",
    "y, X = dmatrices('correct ~ user_id+log_id+sequence_id', data=data_csv, return_type='dataframe')\n",
    "#create DataFrame to hold VIF values\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df['variable'] = X.columns\n",
    "\n",
    "#calculate VIF for each predictor variable\n",
    "vif_df['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "#view VIF for each predictor variable\n",
    "print(vif_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multicollinearity is not present in this dataset as VIF is smaller than 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>log_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>skill_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478035</td>\n",
       "      <td>7014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478043</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478053</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478069</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50964</td>\n",
       "      <td>167478041</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     log_id  item_id  correct  skill_id  timestamp\n",
       "0    50121  167478035     7014      0.0      7014          0\n",
       "1    50121  167478043     7014      1.0      7014          0\n",
       "2    50121  167478053     7014      1.0      7014          0\n",
       "3    50121  167478069     7014      1.0      7014          0\n",
       "4    50964  167478041     7014      1.0      7014          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_csv = data_csv.rename(columns={'sequence_id': \"item_id\"})\n",
    "data_csv[\"skill_id\"] = data_csv[\"item_id\"]\n",
    "data_csv[\"timestamp\"] = np.zeros(len(data_csv), dtype=np.int64)\n",
    "data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>log_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>skill_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>683801.000000</td>\n",
       "      <td>6.838010e+05</td>\n",
       "      <td>683801.000000</td>\n",
       "      <td>683801.000000</td>\n",
       "      <td>683801.000000</td>\n",
       "      <td>683801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>294948.812122</td>\n",
       "      <td>1.693978e+08</td>\n",
       "      <td>22753.185753</td>\n",
       "      <td>0.731761</td>\n",
       "      <td>22753.185753</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48033.447912</td>\n",
       "      <td>3.594528e+06</td>\n",
       "      <td>41869.791331</td>\n",
       "      <td>0.443043</td>\n",
       "      <td>41869.791331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50121.000000</td>\n",
       "      <td>1.509145e+08</td>\n",
       "      <td>5898.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5898.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>278695.000000</td>\n",
       "      <td>1.659241e+08</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>295262.000000</td>\n",
       "      <td>1.703996e+08</td>\n",
       "      <td>9424.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9424.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>333872.000000</td>\n",
       "      <td>1.721740e+08</td>\n",
       "      <td>14442.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14442.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>362374.000000</td>\n",
       "      <td>1.754827e+08</td>\n",
       "      <td>236309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>236309.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        log_id        item_id        correct  \\\n",
       "count  683801.000000  6.838010e+05  683801.000000  683801.000000   \n",
       "mean   294948.812122  1.693978e+08   22753.185753       0.731761   \n",
       "std     48033.447912  3.594528e+06   41869.791331       0.443043   \n",
       "min     50121.000000  1.509145e+08    5898.000000       0.000000   \n",
       "25%    278695.000000  1.659241e+08    7020.000000       0.000000   \n",
       "50%    295262.000000  1.703996e+08    9424.000000       1.000000   \n",
       "75%    333872.000000  1.721740e+08   14442.000000       1.000000   \n",
       "max    362374.000000  1.754827e+08  236309.000000       1.000000   \n",
       "\n",
       "            skill_id  timestamp  \n",
       "count  683801.000000   683801.0  \n",
       "mean    22753.185753        0.0  \n",
       "std     41869.791331        0.0  \n",
       "min      5898.000000        0.0  \n",
       "25%      7020.000000        0.0  \n",
       "50%      9424.000000        0.0  \n",
       "75%     14442.000000        0.0  \n",
       "max    236309.000000        0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv = data_csv[data_csv[\"correct\"].isin([0, 1])]\n",
    "data_csv[\"correct\"] = data_csv[\"correct\"].astype(np.int32)\n",
    "data_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>log_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>skill_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>167477835</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>167477856</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>167477877</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>167477884</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>167477890</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     log_id  item_id  correct  skill_id  timestamp\n",
       "17        0  167477835       92        0        92          0\n",
       "18        0  167477856       92        0        92          0\n",
       "19        0  167477877       92        1        92          0\n",
       "20        0  167477884       92        0        92          0\n",
       "21        0  167477890       92        1        92          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv = data_csv.groupby(\"user_id\").filter(lambda x: len(x) >= 10)\n",
    "data_csv = data_csv[~data_csv[\"skill_id\"].isnull()]\n",
    "data_csv[\"user_id\"] = np.unique(data_csv[\"user_id\"], return_inverse=True)[1]\n",
    "data_csv[\"item_id\"] = np.unique(data_csv[\"item_id\"], return_inverse=True)[1]\n",
    "data_csv[\"skill_id\"] = np.unique(data_csv[\"skill_id\"], return_inverse=True)[1]\n",
    "data_csv.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, I want to re-structure the dataset as following:\n",
    "\n",
    "- Each row corresponds to one students\n",
    "- The user_id is discarded to avoid overfitting\n",
    "- Each row has two columns: The first column includes the list of questions that the student took. The second column includes the result of student's answer respectively. The questions are sorted in chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list of sequence_ids into string\n",
    "def convert(list):\n",
    "    s = [str(i) for i in list]\n",
    "    res = \",\".join(s)\n",
    "    return(res)\n",
    "#sort data by log_id\n",
    "data_csv = data_csv.sort_values(by=[\"log_id\"])\n",
    "\n",
    "group = data_csv.groupby(\"user_id\")\n",
    "preprocessed_data = pd.DataFrame(columns=[\"sequence_ids\", \"correctness\"])\n",
    "n_user = len(group)\n",
    "for user_id in range(n_user):\n",
    "    user_data = group.get_group(user_id)\n",
    "    sequence_ids = user_data[\"item_id\"].values\n",
    "    correctness = user_data[\"correct\"].values\n",
    "    preprocessed_data.loc[user_id] = [convert(sequence_ids), convert(correctness)]\n",
    "#write preprocessed data to csv file\n",
    "preprocessed_data.to_csv(\"./data/preprocessed_data.csv\", sep=\"\\t\", index=False)\n",
    "#separate preprocessed data into train and test sets\n",
    "train_data = preprocessed_data[: int(0.8 * len(preprocessed_data))]\n",
    "test_data = preprocessed_data[int(0.8 * len(preprocessed_data)) :]\n",
    "#write train and test data to csv files\n",
    "train_data.to_csv(\"./data/assist2015_train.csv\", sep=\"\\t\", index=False, header=False)\n",
    "test_data.to_csv(\"./data/assist2015_test.csv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: The implementation of this model heavily relies on https://github.com/jdxyw/deepKT/tree/master. Due to time constraint, I decided to only understand what the code does, instead of implementing from the beginning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.001\n",
    "        self.batch_size = 64\n",
    "        self.epoch = 15\n",
    "        self.dropout = 0.2\n",
    "        self.num_skill = 100\n",
    "        self.embed_dim = 200\n",
    "        self.num_heads = 5\n",
    "        self.num_worker = 0\n",
    "args = args()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our Dataset that subclasses `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils\n",
    "import numpy as np\n",
    "\n",
    "class SAKTDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    __init__ function:\n",
    "    df: the preprocessed data.\n",
    "    n_skill: the number of unique sequence_id (for this dataset, 100).\n",
    "    max_len: the fixed length of each input sequence.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, n_skill, max_len=200):\n",
    "        super(SAKTDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.n_skill = n_skill\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \"\"\"__getitem__ function: this function is called when you index a SAKTDataset object.\n",
    "    idx: the index of the data point.\n",
    "    return: a tuple of four tensors: the encoded question id + correct answer, \n",
    "            the question id, the correct answer, and the mask. All are padded to the same length.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        qids = self.df[0][idx].split(\",\")\n",
    "        correct = self.df[1][idx].split(\",\")\n",
    "\n",
    "        #if the length of the sequence is greater than max_len, only use the last max_len elements\n",
    "        if len(qids) > self.max_len:\n",
    "            qids = qids[-self.max_len :]\n",
    "            correct = correct[-self.max_len :]\n",
    "\n",
    "        qids = np.array(list(map(int, qids)))\n",
    "        correct = np.array(list(map(int, correct)))\n",
    "\n",
    "        #encode question id + correct answer into one number\n",
    "        qa = qids + correct * self.n_skill\n",
    "\n",
    "        #create paddings\n",
    "        q = np.ones(self.max_len, dtype=int) * self.n_skill\n",
    "        qa2 = np.ones(self.max_len, dtype=int) * (self.n_skill * 2 + 1)\n",
    "        correct2 = np.ones(self.max_len, dtype=int) * -1\n",
    "        mask = np.zeros(self.max_len, dtype=int)\n",
    "\n",
    "        #fill in the paddings\n",
    "        q[: len(qids)] = qids\n",
    "        qa2[: len(qa)] = qa\n",
    "        correct2[: len(correct)] = correct\n",
    "        mask[: len(qa)] = np.ones(len(qa), dtype=int)\n",
    "\n",
    "        return (\n",
    "            torch.cat(\n",
    "                (torch.LongTensor([2 * self.n_skill]), torch.LongTensor(qa2[:-1]))\n",
    "            ),\n",
    "            torch.LongTensor(q),\n",
    "            torch.LongTensor(correct2),\n",
    "            torch.LongTensor(mask),\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    #iterate over each batch of the dataset (train_iterator is the Dataloader object)\n",
    "    for i, (qa, qid, labels, mask) in enumerate(train_iterator):\n",
    "        qa, qid, labels, mask = (\n",
    "            qa.to(device),\n",
    "            qid.to(device),\n",
    "            labels.to(device),\n",
    "            mask.to(device),\n",
    "        ) #move data to device (cpu or gpu)\n",
    "\n",
    "        optim.zero_grad() #reset the gradients to zero\n",
    "        logits, _ = model(qid, qa) #call the forward function of the model\n",
    "        loss = criterion(logits, labels, qid, mask, device=device) #calculate the loss\n",
    "        loss.backward() #backpropagation\n",
    "        optim.step() #update the parameters\n",
    "        \n",
    "def future_mask(seq_length):\n",
    "    #create a mask that prevents the model from attending to future steps\n",
    "    mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype(\"bool\")\n",
    "    return torch.from_numpy(mask)\n",
    "\n",
    "\n",
    "def eval_epoch(model, test_iterator, criterion, eval_func, device=\"cpu\"):\n",
    "    #set the model to evaluation mode\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    preds, binary_preds, targets = [], [], []\n",
    "    for i, (qa, qid, labels, mask) in enumerate(test_iterator):\n",
    "        qa, qid, labels, mask = (\n",
    "            qa.to(device),\n",
    "            qid.to(device),\n",
    "            labels.to(device),\n",
    "            mask.to(device),\n",
    "        )\n",
    "        \n",
    "        #do not calculate the gradients\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(qid, qa)\n",
    "\n",
    "        loss = criterion(logits, labels, qid, mask, device=device)\n",
    "        eval_loss.append(loss.detach().item())\n",
    "\n",
    "        mask = mask.eq(1)\n",
    "        pred, binary_pred, target = eval_func(logits, qid, labels, mask)\n",
    "        preds.append(pred)\n",
    "        binary_preds.append(binary_pred)\n",
    "        targets.append(target)\n",
    "\n",
    "    #concatenate the results from all batches\n",
    "    preds = np.concatenate(preds)\n",
    "    binary_preds = np.concatenate(binary_preds)\n",
    "    targets = np.concatenate(targets)\n",
    "\n",
    "    #auc is the area under the ROC curve (receiver operating characteristic curve). \n",
    "    #It is a metric for binary classification. Larger auc means better performance.\n",
    "    auc_value = roc_auc_score(targets, preds)\n",
    "    #accuracy is the number of correct predictions divided by the total number of predictions.\n",
    "    accuracy = accuracy_score(targets, binary_preds)\n",
    "    #precision is the number of true positives divided by the number of true positives and false positives.\n",
    "    #recall is the number of true positives divided by the number of true positives and false negatives.\n",
    "    precision, recall, f_score, _ = precision_recall_fscore_support(\n",
    "        targets, binary_preds\n",
    "    )\n",
    "    #positive rate is the number of positive labels divided by the total number of labels.\n",
    "    #for this dataset, pos_rate is high\n",
    "    pos_rate = np.sum(targets) / float(len(targets))\n",
    "    print(\n",
    "        \"auc={0}, accuracy={1}, precision={2}, recall={3}, fscore={4}, pos_rate={5}\".format(\n",
    "            auc_value, accuracy, precision, recall, f_score, pos_rate\n",
    "        )\n",
    "    )\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, state_size=200, dropout=0.2):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.dropout = dropout\n",
    "        self.lr1 = nn.Linear(self.state_size, self.state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr2 = nn.Linear(self.state_size, self.state_size)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class SAKTModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_skill, embed_dim, dropout, num_heads=4, max_len=64, device=\"cpu\"\n",
    "    ):\n",
    "        super(SAKTModel, self).__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.q_embed_dim = embed_dim\n",
    "        self.qa_embed_dim = embed_dim\n",
    "        self.pos_embed_dim = embed_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout = dropout\n",
    "        self.num_heads = num_heads\n",
    "        self.max_len = max_len\n",
    "        self.device = device\n",
    "\n",
    "        self.q_embedding = nn.Embedding(\n",
    "            n_skill + 1, self.q_embed_dim, padding_idx=n_skill\n",
    "        )\n",
    "        self.qa_embedding = nn.Embedding(\n",
    "            2 * n_skill + 2, self.qa_embed_dim, padding_idx=2 * n_skill + 1\n",
    "        )\n",
    "        self.pos_embedding = nn.Embedding(self.max_len, self.pos_embed_dim)\n",
    "\n",
    "        self.multi_attention = nn.MultiheadAttention(\n",
    "            embed_dim=self.embed_dim, num_heads=self.num_heads, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        self.key_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.value_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.query_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.embed_dim)\n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "        self.ffn = FFN(self.embed_dim)\n",
    "        self.pred = nn.Linear(self.embed_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, q, qa):\n",
    "        qa = self.qa_embedding(qa)\n",
    "        pos_id = torch.arange(qa.size(1)).unsqueeze(0).to(self.device)\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        qa = qa + pos_x # Add positional embedding\n",
    "        q = self.q_embedding(q)\n",
    "\n",
    "        q = q.permute(1, 0, 2)\n",
    "        qa = qa.permute(1, 0, 2)\n",
    "\n",
    "        attention_mask = future_mask(q.size(0)).to(self.device)\n",
    "        attention_out, _ = self.multi_attention(q, qa, qa, attn_mask=attention_mask)\n",
    "        attention_out = self.layer_norm1(attention_out + q)\n",
    "        attention_out = attention_out.permute(1, 0, 2)\n",
    "\n",
    "        x = self.ffn(attention_out)\n",
    "        x = self.dropout_layer(x)\n",
    "        x = self.layer_norm2(x + attention_out)\n",
    "        x = self.pred(x)\n",
    "\n",
    "        return x.squeeze(-1), None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.7167315136552093, accuracy=0.7966361579888882, precision=[0.58610272 0.80557474], recall=[0.1134656  0.97865174], fscore=[0.19012439 0.88371866], pos_rate=0.7896226325802391\n",
      "auc=0.7298259036990143, accuracy=0.7976678371650592, precision=[0.58985201 0.80740763], recall=[0.12552301 0.97674586], fscore=[0.20699633 0.8840406 ], pos_rate=0.7896226325802391\n",
      "auc=0.7281364515559224, accuracy=0.7978855309361779, precision=[0.57743481 0.81031035], recall=[0.14644351 0.97144775], fscore=[0.2336348  0.88359263], pos_rate=0.7896226325802391\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39m#save the weights of the model\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     torch\u001b[39m.\u001b[39msave(sakt\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39m./saved/sakt_weights.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m run()\n",
      "Cell \u001b[1;32mIn[28], line 45\u001b[0m, in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(args\u001b[39m.\u001b[39mepoch):\n\u001b[1;32m---> 45\u001b[0m     utils\u001b[39m.\u001b[39;49mtrain_epoch(sakt, train_dataloader, optimizer, loss_func,\n\u001b[0;32m     46\u001b[0m                              device)\n\u001b[0;32m     47\u001b[0m     utils\u001b[39m.\u001b[39meval_epoch(sakt, test_dataloader, loss_func, utils\u001b[39m.\u001b[39msakt_eval, device)\n\u001b[0;32m     48\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32me:\\Huy_Code\\knowledge-tracing\\utils.py:34\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_iterator, optim, criterion, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m qa, qid, labels, mask \u001b[39m=\u001b[39m (\n\u001b[0;32m     27\u001b[0m     qa\u001b[39m.\u001b[39mto(device),\n\u001b[0;32m     28\u001b[0m     qid\u001b[39m.\u001b[39mto(device),\n\u001b[0;32m     29\u001b[0m     labels\u001b[39m.\u001b[39mto(device),\n\u001b[0;32m     30\u001b[0m     mask\u001b[39m.\u001b[39mto(device),\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 34\u001b[0m logits, _ \u001b[39m=\u001b[39m model(qid, qa)\n\u001b[0;32m     35\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, labels, qid, mask, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     36\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Huy_Code\\knowledge-tracing\\model.py:140\u001b[0m, in \u001b[0;36mSAKTModel.forward\u001b[1;34m(self, q, qa)\u001b[0m\n\u001b[0;32m    137\u001b[0m qa \u001b[39m=\u001b[39m qa\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    139\u001b[0m attention_mask \u001b[39m=\u001b[39m future_mask(q\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 140\u001b[0m attention_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulti_attention(q, qa, qa, attn_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[0;32m    141\u001b[0m attention_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm1(attention_out \u001b[39m+\u001b[39m q)\n\u001b[0;32m    142\u001b[0m attention_out \u001b[39m=\u001b[39m attention_out\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[0;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[0;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[0;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:5224\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[0;32m   5223\u001b[0m     \u001b[39massert\u001b[39;00m in_proj_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 5224\u001b[0m     q, k, v \u001b[39m=\u001b[39m _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n\u001b[0;32m   5225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5226\u001b[0m     \u001b[39massert\u001b[39;00m q_proj_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:4777\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[1;34m(q, k, v, w, b)\u001b[0m\n\u001b[0;32m   4775\u001b[0m     b_q, b_kv \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39msplit([E, E \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m])\n\u001b[0;32m   4776\u001b[0m q_proj \u001b[39m=\u001b[39m linear(q, w_q, b_q)\n\u001b[1;32m-> 4777\u001b[0m kv_proj \u001b[39m=\u001b[39m linear(k, w_kv, b_kv)\n\u001b[0;32m   4778\u001b[0m \u001b[39m# reshape to 2, E and not E, 2 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[0;32m   4779\u001b[0m kv_proj \u001b[39m=\u001b[39m kv_proj\u001b[39m.\u001b[39munflatten(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, (\u001b[39m2\u001b[39m, E))\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import utils\n",
    "from loss import SAKTLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "def run():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_df = pd.read_csv(\"./data/assist2015_train.csv\",\n",
    "                           header=None,\n",
    "                           sep='\\t')\n",
    "    test_df = pd.read_csv(\"./data/assist2015_test.csv\", header=None, sep='\\t')\n",
    "\n",
    "    train = SAKTDataset(train_df, args.num_skill, max_len=128)\n",
    "    test = SAKTDataset(test_df, args.num_skill, max_len=128)\n",
    "    train_dataloader = DataLoader(train,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  num_workers=args.num_worker,\n",
    "                                  shuffle=True)\n",
    "    test_dataloader = DataLoader(test,\n",
    "                                 batch_size=args.batch_size * 2,\n",
    "                                 num_workers=args.num_worker,\n",
    "                                 shuffle=False)\n",
    "\n",
    "    sakt = SAKTModel(args.num_skill, args.embed_dim, args.dropout, args.num_heads, device=device, max_len=128)\n",
    "\n",
    "    optimizer = torch.optim.Adam(sakt.parameters(), lr=args.learning_rate)\n",
    "    loss_func = SAKTLoss()\n",
    "\n",
    "    sakt.to(device)\n",
    "    loss_func.to(device)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    for epoch in range(args.epoch):\n",
    "        utils.train_epoch(sakt, train_dataloader, optimizer, loss_func,\n",
    "                                 device)\n",
    "        utils.eval_epoch(sakt, test_dataloader, loss_func, utils.sakt_eval, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "    #save the weights of the model\n",
    "    torch.save(sakt.state_dict(), './saved/sakt_weights.pth')\n",
    "run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the accuracy of the next question, you can use query function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#load the model sakt_all.pth\n",
    "MODEL_PATH = \"./saved/sakt_weights.pth\"\n",
    "model = SAKTModel(args.num_skill, args.embed_dim, args.dropout, args.num_heads, max_len=128)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "train_df = pd.read_csv(\"./data/assist2015_train.csv\",\n",
    "                           header=None,\n",
    "                           sep='\\t')\n",
    "train = SAKTDataset(train_df, 100, max_len=128)\n",
    "train_dataloader = DataLoader(train,\n",
    "                            batch_size=args.batch_size,\n",
    "                            num_workers=args.num_worker,\n",
    "                            shuffle=True)\n",
    "\n",
    "def query(prev_qid, prev_correct, cur_qid):\n",
    "    prev_qid = np.array(prev_qid)\n",
    "    prev_correct = np.array(prev_correct)\n",
    "    qa = prev_qid + 100 * prev_correct\n",
    "    padding_qa = np.ones(128, dtype=np.int8) * 201\n",
    "    padding_qa[:len(qa)] = qa\n",
    "    qid = prev_qid.copy().tolist()\n",
    "    qid.append(cur_qid)\n",
    "    qid = np.array(qid)\n",
    "    padding_qid = np.ones(128, dtype=np.int8) * 100\n",
    "    padding_qid[:len(qid)] = qid \n",
    "    padding_qa = torch.LongTensor(np.array([padding_qa]))\n",
    "    padding_qid = torch.LongTensor(np.array([padding_qid]))\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(padding_qid, padding_qa)\n",
    "    logits = torch.sigmoid(logits)\n",
    "    prob = logits[0][len(prev_qid)].detach().numpy()\n",
    "    return int(prob * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowlegde-tracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
